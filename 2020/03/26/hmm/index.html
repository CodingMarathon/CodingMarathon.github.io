<!DOCTYPE HTML>
<html lang="zh-CN">


<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <meta name="keywords" content="HMM详解, BUAA NLP DeepLearning Knowledge Graph">
    <meta name="baidu-site-verification" content="YBVxcnPira">
    <meta name="description" content="1 隐马尔科夫模型本文主要介绍NLP领域中很重要的一个模型——隐马尔科夫模型（Hidden Markov Model，HMM）。希望读完本文后，大家能够清楚地理解HMM并能够应用到实际中。  
隐马尔科夫模型是结构最简单的动态贝叶斯网（dy">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>HMM详解 | CodingMarathon</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    <style type="text/css">
        
    </style>

    <script src="/libs/jquery/jquery-2.2.0.min.js"></script>
    <script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script>
    <script>
        var _hmt = _hmt || [];
        (function () {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?46e79e71af0709a5b9106bf20cecc493";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>

    
        <script>
            (function(){
                var bp = document.createElement('script');
                var curProtocol = window.location.protocol.split(':')[0];
                if (curProtocol === 'https') {
                    bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
                }
                else {
                    bp.src = 'http://push.zhanzhang.baidu.com/push.js';
                }
                var s = document.getElementsByTagName("script")[0];
                s.parentNode.insertBefore(bp, s);
            })();
        </script>
    

    <script>
        (function(){
        var src = "https://jspassport.ssl.qhimg.com/11.0.1.js?d182b3f28525f2db83acfaaf6e696dba";
        document.write('<script src="' + src + '" id="sozz"><\/script>');
        })();
    </script>

<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>

<body>

    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">CodingMarathon</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right">
    
    <li class="hide-on-med-and-down">
        <a href="/" class="waves-effect waves-light">
            
            <i class="fa fa-home"></i>
            
            <span>首页</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/tags" class="waves-effect waves-light">
            
            <i class="fa fa-tags"></i>
            
            <span>标签</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/categories" class="waves-effect waves-light">
            
            <i class="fa fa-bookmark"></i>
            
            <span>分类</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/archives" class="waves-effect waves-light">
            
            <i class="fa fa-archive"></i>
            
            <span>归档</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/about" class="waves-effect waves-light">
            
            <i class="fa fa-user-circle-o"></i>
            
            <span>关于</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/friends" class="waves-effect waves-light">
            
            <i class="fa fa-address-book"></i>
            
            <span>友情链接</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/contact" class="waves-effect waves-light">
            
            <i class="fa fa-comments"></i>
            
            <span>留言板</span>
        </a>
    </li>
    
    <li>
        <a href="#searchModal" class="modal-trigger waves-effect waves-light">
            <i id="searchIcon" class="fa fa-search" title="搜索"></i>
        </a>
    </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">CodingMarathon</div>
        <div class="logo-desc">
            
            主题拷贝自https://github.com/hexojs/hexo/，目前没时间更改，进站只需看博客就行！
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li>
            <a href="/" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-home"></i>
                
                首页
            </a>
        </li>
        
        <li>
            <a href="/tags" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-tags"></i>
                
                标签
            </a>
        </li>
        
        <li>
            <a href="/categories" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-bookmark"></i>
                
                分类
            </a>
        </li>
        
        <li>
            <a href="/archives" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-archive"></i>
                
                归档
            </a>
        </li>
        
        <li>
            <a href="/about" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-user-circle-o"></i>
                
                关于
            </a>
        </li>
        
        <li>
            <a href="/friends" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-address-book"></i>
                
                友情链接
            </a>
        </li>
        
        <li>
            <a href="/contact" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-comments"></i>
                
                留言板
            </a>
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/CodingMarathon/hexo-matery-modified" class="waves-effect waves-light" target="_blank">
                <i class="fa fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/CodingMarathon/hexo-matery-modified" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/27.jpg')">
    <div class="container">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        HMM详解
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>



<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 20px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        <span class="chip bg-color">无标签</span>
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2020-03-26
                </div>

                <div class="post-author info-break-policy">
                    <i class="fa fa-user-o fa-fw"></i>作者:&nbsp;&nbsp;
                    
                    CodingMarathon
                    
                </div>

                
                
                <div class="info-break-policy">
                    <i class="fa fa-file-word-o fa-fw"></i>文章字数:&nbsp;&nbsp;
                    9.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="fa fa-clock-o fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    43 分
                </div>
                
                

                
                <div id="busuanzi_container_page_pv" class="info-break-policy">
                    <i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                    <span id="busuanzi_value_page_pv"></span>
                </div>
                
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="1-隐马尔科夫模型"><a href="#1-隐马尔科夫模型" class="headerlink" title="1 隐马尔科夫模型"></a>1 隐马尔科夫模型</h1><p>本文主要介绍NLP领域中很重要的一个模型——<strong>隐马尔科夫模型（Hidden Markov Model，HMM）</strong>。希望读完本文后，大家能够清楚地理解<strong>HMM</strong>并能够应用到实际中。  </p>
<p>隐马尔科夫模型是结构最简单的<strong>动态贝叶斯网（dynamic Bayesian network，也被称作有向图模型）</strong>，HMM是可以用于标注问题的统计数学模型，描述由隐藏的<strong>马尔科夫链</strong>随机生成观测序列的过程，属于<strong>生成模型</strong>。HMM模型在语音识别、自然语言处理、生物信息、模式识别等领域有广泛的应用。</p>
<h2 id="1-1-HMM解决的问题"><a href="#1-1-HMM解决的问题" class="headerlink" title="1.1 HMM解决的问题"></a>1.1 HMM解决的问题</h2><p>首先看看什么样的问题可以使用HMM模型解决。</p>
<p>使用HMM模型来解决的问题一般有两个特征：</p>
<ul>
<li>1） 问题是基于序列的，比如时间序列、状态序列。</li>
<li>2 ）问题中有两类数据，一类序列数据是可以观测到的，即<strong>观测序列</strong>；而另一类数据是不能观察到的，即<strong>隐藏状态序列</strong>，简称<strong>状态序列</strong>。</li>
</ul>
<p>如果问题有了这两个特征，那么这个问题一般可以使用HMM模型尝试解决，这样的问题在生活中是很多的。例如，说一句话，发出的声音是观测序列，想表达的意思是隐藏状态序列；写文章的过程可以想象为先在脑海中构思好一个满足语法的词性序列，然后再将每个词性填充为具体的词语。</p>
<h2 id="1-2-HMM模型的定义"><a href="#1-2-HMM模型的定义" class="headerlink" title="1.2 HMM模型的定义"></a>1.2 HMM模型的定义</h2><p>隐马尔科夫模型是关于时序的概率模型，描述由一个隐藏的<strong>马尔科夫链</strong>随机生成不可观测的状态随机序列，再由各个状态生成一个观测而产生观测随机序列的过程（摘自《统计学习方法》）。隐藏的马尔科夫链随机生成的状态的序列，称为<strong>状态序列（state sequence）</strong>，记作$\boldsymbol{y}$；每个状态生成一个观测，而由此产生的观测的随机序列，称为<strong>观测序列（observation sequence）</strong>，记作$\boldsymbol{x}$。序列的每一个位置又可以看作一个时刻。<br><img src="https://img-blog.csdnimg.cn/20200316182133870.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0VsZW5zdG9uZQ==,size_16,color_FFFFFF,t_70" alt="HMM模型示意图"></p>
<center><font size="4"><strong>HMM模型示意图</strong></font></center>

<h3 id="1-2-1HMM的两个假设"><a href="#1-2-1HMM的两个假设" class="headerlink" title="1.2.1HMM的两个假设"></a>1.2.1HMM的两个假设</h3><p>首先介绍一下马尔科夫假设：每个事件的发生概率只取决于前一个事件。将满足该假设的连续多个事件串联在一起，就构成了<strong>马尔科夫链</strong>。在NLP语境下，可以将事件具象为单词，于是马尔科夫模型就是二元语法。</p>
<ul>
<li>第一个假设：将马尔科夫假设作用于状态序列，假设当前状态$y_t$仅仅依赖于前一个状态$y_{t-1}$，连续多个状态构成隐马尔科夫链$\boldsymbol{y}$。数学表达式为：<br>  $$p(y_t|y_{t-1},x_{t-1},y_{t-2},x_{t-2},y_{t-3},x_{t-3},…,y_{1},x_1)=p(y_t|y_{t-1}), t=1,2,3,…,T$$</li>
</ul>
<p>有了隐马尔科夫链，如何建立与观测序列$\boldsymbol{x}$的联系呢？HMM做了第二个假设:</p>
<ul>
<li>第二个假设：任意时刻的观测$x_t$只依赖于该时刻的状态$y_t$，与其他时刻的状态或观测独立无关。数学表达式为：<br> $$p(x_t|y_T,x_T,y_{t-1},x_{t-1},…,y_{t+1},x_{t+1},y_t,y_{t-1},x_{t-1},…y_1,x_1)=p(x_t|y_t),t=1,2,3,…,T$$</li>
</ul>
<h3 id="1-2-2-HMM模型"><a href="#1-2-2-HMM模型" class="headerlink" title="1.2.2 HMM模型"></a>1.2.2 HMM模型</h3><p>设$Q$是所有可能的状态的集合，$V$是所有可能的观测的集合。<br>$$Q=\{q_1,q_2,…,q_N\}，V=\{v_1,v_2,v_3,…,v_N\}$$<br>其中，N是可能的状态数，M是可能的观测数。<br>HMM模型用三元组来表示$\lambda=(\boldsymbol{\pi},A,B)$：</p>
<ul>
<li>$\boldsymbol{\pi}$ : 初始状态概率向量</li>
<li>A：状态转移概率矩阵</li>
<li>B：发射概率矩阵</li>
</ul>
<p><strong>系统怎么从零开始呢？</strong> 观测值是由隐藏状态产生的，所以系统最初应该是生成隐藏状态。</p>
<p><strong>初始概率向量</strong>指的是系统启动时进入的第一个状态$y_1$成为<strong>初始状态</strong>，$\boldsymbol{y}$有$N$种取值，从$Q$集合中选取一个，即$\boldsymbol{y} \in \{q_1,q_2,…,q_N\}$。由于$y_1$是第一个状态，是一个独立的离散随机变量，可以用$p(y_1|\boldsymbol{\pi})$来描述，$y_1$只由$\boldsymbol{\pi}$来控制，其中$\boldsymbol{\pi}=(\pi_1,\pi_2,\pi_3,…,\pi_N)^T,0\leq\pi_i\leq1,\sum\limits^{N}_{i=1}{\pi_i}$=1。$\boldsymbol{\pi}$是概率分布的参数向量，称为<strong>初始状态概率向量</strong>。给定$\boldsymbol{\pi}$，初始状态$y_1$的取值分布就确定了。以中文分词问题为例，采用{B,M,E,S}标记时，其中B代表一个词的第一个字，M代表词的中间字，E代表词的末尾字，S代表单字成词。$y_1$所有可能的取值及对应的概率如下：</p>
<p>$$p(y_1=B)=0.7$$</p>
<p>$$p(y_1=M)=0$$</p>
<p>$$p(y_1=E)=0$$</p>
<p>$$p(y_1=s)=0.3$$</p>
<p>则$\pi=[0.7,0,0,0.3]$，也就是说句子第一个字可能是一个单字或者一个词的首字，不可能是一个词的中间或者尾字。</p>
<p>$y_1$<strong>确定之后，怎么产生</strong>$x_1$<strong>呢？如何确定</strong>$x_1$<strong>的概率分布呢？</strong></p>
<p>根据第二个假设：当前观测值$x_1$仅取决于当前的状态$y_1$，对于从$Q$中取出的每一种状态$y_1$，$x_1$都可以从$V$集合中的$M$个值选一个，所以对于每一个$y,x$都是一个独立的离散随机变量，其概率参数对应一个向量，维度为$M$，即$\boldsymbol{x} \in \{v_1,v_2,…,v_N\}$。由于一共有$N$种$y$，所以这些向量构成了一个$N\times M$矩阵，称为<strong>发射概率矩阵</strong>$\boldsymbol{B}$。<br>$$\boldsymbol{B}=[b_{ij}]_{N\times M}=[p(x_t=v_i|y_t=q_j)]_{N\times M}$$</p>
<p>其中，$p(x_t=v_i|y_t=q_j)$代表t时刻，隐藏状态$y_t$是$q_j$，由这个状态产生的观测值$x_t$等于$v_i$的概率。</p>
<table>
<thead>
<tr>
<th>状态</th>
<th>观测值1</th>
<th>观测值2</th>
<th>…</th>
<th>观测值M</th>
</tr>
</thead>
<tbody><tr>
<td>状态1</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>状态2</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>…</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>状态N</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>发射概率矩阵是一个非常形象的术语：可以将$\boldsymbol{y}$想象成为不同的彩弹枪，$\boldsymbol{x}$为不同颜色的子弹，每把彩弹枪内的颜色子弹比例不一样，导致有的彩弹枪红色子弹较多比较容易发射红色彩弹，一些彩弹枪绿色子弹较多更容易发射绿色彩弹。<br>发射概率在中文分词中也具有实际意义，有些字符构词的位置比较固定，比如一把作为词首的枪，不容易发射出“餮”，因为“餮”一般作为“饕餮”的词尾出现。通过给$p(x_1=餮|y_1=B)$较低的概率，HMM模型可以有效的防止“饕餮”被错误的切分。</p>
<p>$y_1$<strong>确定之后，如何转移状态到</strong>$y_2$<strong>?乃至</strong>$y_n$<strong>？</strong></p>
<p>根据HMM模型的第一个假设：$t+1$时刻的状态仅仅取决于$t$时刻的状态。类似发射概率矩阵，对于$t$时刻的每一种状态，$y_{t+1}$是一个离散的随机变量，取值有$N$种。$t$时刻一共可能有$N$种状态，所以从$t$时刻到$t+1$时刻的状态转移矩阵为$N\times N$的方阵，称为<strong>状态转移概率矩阵</strong>$\boldsymbol{A}$:<br>$$\boldsymbol{A}=[a_{ij}]_{N\times N}=[p(y_{t+1}=v_j|y_t=v_i)]_{N\times N}$$</p>
<p>其中，$p(y_{t+1}=s_j|y_t=s_i)$表示$t$时刻的状态为$v_i$，$t+1$时刻的状态为$v_j$的概率。</p>
<table>
<thead>
<tr>
<th>当前状态</th>
<th>下一状态是状态1</th>
<th>状态2</th>
<th>…</th>
<th>状态N</th>
</tr>
</thead>
<tbody><tr>
<td>状态1</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>状态2</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>…</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>状态N</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>例如，在中文分词中，标签B后面不可能是S，于是给$p(y_{t+1}=S|y_t=B)=0$就可以防止B后面接S的情况出现。</p>
<p><strong>初始状态概率向量、状态转移概率矩阵与发射概率矩阵</strong>称为HMM模型的三元组$\lambda=(\boldsymbol{\pi},A,B)$，只要三元组确定了，HMM模型就确定了。</p>
<p>举一个经典的例子：<br>假设有四个盒子，每个盒子里都装有红白两种颜色的球，如下表：</p>
<table>
<thead>
<tr>
<th>盒子</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
</tr>
</thead>
<tbody><tr>
<td>红球数</td>
<td>5</td>
<td>3</td>
<td>6</td>
<td>8</td>
</tr>
<tr>
<td>白球数</td>
<td>5</td>
<td>7</td>
<td>4</td>
<td>2</td>
</tr>
</tbody></table>
<p><img src="https://img-blog.csdnimg.cn/20200317083002437.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0VsZW5zdG9uZQ==,size_16,color_FFFFFF,t_70" alt="盒子示意"><br>按照下面的方法抽球，产生一个球的颜色观察序列：</p>
<ol>
<li><p>从4个盒子里以等概率随机选取一个盒子，从这个盒子里随机抽取一个球，记录颜色后，放回；</p>
</li>
<li><p>从当前盒子随机转移到下一个盒子，规则是：如果当前盒子是盒子1，那么下一个盒子一定是盒子2，如果当前是盒子2或者3，那么分别以概率0.4和0.6转移到左边或右边的盒子，如果当前盒子是4，那么各以0.5的概率停留在盒子4或者转移到盒子3；</p>
</li>
<li><p>确定转移盒子后，再从这个盒子里随机抽取一个球，记录其颜色，放回；</p>
</li>
<li><p>重复2,3步骤3次</p>
<p>一共抽取出来5个球，得到一个球的颜色观察序列：<br>$$\boldsymbol{x}=\{\color{red}红，红，\color{black}白，白，\color{red}红\}$$</p>
<p>在这个过程中，观察者只能观测到球的颜色序列，观测不到球是从哪个盒子取出的，即观察不到盒子的序列。<br>这个例子中有两个随机序列，一个是盒子的序列（状态序列），一个是球的颜色的观测序列（观测序列），前者是隐藏的，后者是可以观测的。根据所给的条件可以明确状态集合、观测集合、序列长度以及模型的三要素。</p>
<ul>
<li>状态集合是$Q=\{盒子1，盒子2，盒子3，盒子4\}，N=4$。</li>
<li>观测集合是$V=\{\color{red}红，\color{black}白\}$。</li>
<li>状态序列和观测序列的长度$T=5$，原因是一共观测了5次。</li>
<li>初始状态概率向量为$\boldsymbol{\pi}=(0.25,0.25,0.25,0.25)^T$，原因是第一次是等概率随机抽取一个盒子。</li>
<li>状态转移概率矩阵$A=\begin{bmatrix}<br>0 &amp; 1 &amp; 0 &amp; 0 \<br>0.4 &amp; 0 &amp; 0.6 &amp; 0\<br>0 &amp; 0.4 &amp; 0 &amp;0.6\<br>0 &amp; 0 &amp; 0.5 &amp; 0.5<br>\end{bmatrix}$</li>
<li>发射概率矩阵$B=\begin{bmatrix}<br>0.5 &amp; 0.5 \<br>0.3 &amp; 0.7 \<br>0.6 &amp; 0.4 \<br>0.8 &amp; 0.2 \<br>\end{bmatrix}$</li>
</ul>
</li>
</ol>
<h2 id="1-3-HMM模型的三个基本问题"><a href="#1-3-HMM模型的三个基本问题" class="headerlink" title="1.3 HMM模型的三个基本问题"></a>1.3 HMM模型的三个基本问题</h2><p>有了HMM模型之后，如何使用模型呢？HMM模型一个可以解决三个问题：</p>
<ol>
<li><strong>概率计算问题</strong>：给定模型参数$\lambda=(\boldsymbol{\pi},A,B)$，和一个观测序列$\boldsymbol{x}$,，计算在这个模型参数$\lambda$下，观测序列出现的最大概率，即$p(\boldsymbol{x}|\lambda)$的最大值。</li>
<li><strong>模型训练问题</strong>：给定训练集$(\boldsymbol{x}^{(i)},\boldsymbol{y}^{(i)})$，估计模型参数$\lambda=(\boldsymbol{\pi},A,B)$，使得在该模型下观测序列概率$p(\boldsymbol{x}|\lambda)$最大，即使用极大似然估计得方法估计参数。</li>
<li><strong>序列预测问题</strong>：也称为解码问题，已知模型参数$\lambda=(\boldsymbol{\pi},A,B)$，给定观测序列$\boldsymbol{x}$，求最有可能的状态序列$\boldsymbol{y}$，即求$p(\boldsymbol{y}|\boldsymbol{x})$的最大值。</li>
</ol>
<h1 id="2-概率计算问题及算法"><a href="#2-概率计算问题及算法" class="headerlink" title="2 概率计算问题及算法"></a>2 概率计算问题及算法</h1><p>概率计算问题，也就是在给定的模型参数三元组的条件生成观测序列的过程。给定模型参数$\lambda=(\boldsymbol{\pi},A,B)$和一个观测序列$\boldsymbol{x}$,，计算在这个模型参数$\lambda$下，观测序列出现的最大概率，即$p(\boldsymbol{x}|\lambda)$的最大值。先介绍概念上可行但计算上不行的<strong>直接计算法（暴力解法）</strong>，然后介绍<strong>前向算法</strong>与<strong>后向算法</strong>。</p>
<h2 id="2-1-直接计算法"><a href="#2-1-直接计算法" class="headerlink" title="2.1 直接计算法"></a>2.1 直接计算法</h2><p>给定模型参数$\boldsymbol{\lambda}=(\boldsymbol{\pi},A,B)$和一个观测序列$\boldsymbol{x}=\{x_1,x_2,x_3,…x_T\}$，计算观测序列出现的概率$p(\boldsymbol{x}|\lambda)$，最直接的方法就是按照概率公式直接计算，通过列举所有可能的长度为$T$的状态序列$\boldsymbol{y}=\{y_1,y_2,y_3,…,y_T\}$，求各个状态序列$\boldsymbol{y}$与观测序列$\boldsymbol{x}=(x_1,x_2,x_3,…,x_T)$的联合概率$p(\boldsymbol{x},\boldsymbol{y}|\boldsymbol{\lambda})$,，然后对所有可能的状态序列求和，得到$p(\boldsymbol{x}|\boldsymbol{\lambda})$。<br>状态序列$\boldsymbol{y}=(y_1,y_2,y_3,…,y_T)$发生的概率是：<br>$$p(\boldsymbol{y}|\boldsymbol{\lambda})=\pi_{y_1}a_{y_1y_2}a_{y_2y_3}…a_{y_{T-1}y_T}$$</p>
<p>对固定的状态序列$\boldsymbol{y}=(y_1,y_2,y_3,…,y_T)$并且观测序列为$\boldsymbol{x}=(x_1,x_2,x_3,…,x_T)$的概率是：<br>$$p(\boldsymbol{x}|\boldsymbol{y},\boldsymbol{\lambda})=b_{y_1x_1}b_{y_2x_2}b_{y_3x_3}…b_{y_Tx_T}$$</p>
<p>在给定HMM模型参数$\boldsymbol{\lambda}$的条件下，$\boldsymbol{x},\boldsymbol{y}$同时出现的联合概率为：<br>$$\begin{aligned}p(\boldsymbol{x},\boldsymbol{y}|\boldsymbol{\lambda})&amp;=p(\boldsymbol{x}|\boldsymbol{y},\boldsymbol{\lambda})p(\boldsymbol{y}|\boldsymbol{\lambda})\<br>&amp;=\pi_{y_1}b_{y_1x_1}a_{y_1y_2}b_{y_2x_2}a_{y_2y_3}b_{y_3x_3}…a_{y_{T-1}y_T}b_{y_Tx_T}<br>\end{aligned}$$</p>
<p>然后，对所有可能的状态序列$\boldsymbol{y}$求和，得到观测序列$\boldsymbol{x}$的概率$p(\boldsymbol{x}|\lambda)$，即：<br>$$\begin{aligned}<br>p(\boldsymbol{x}|\lambda)&amp;=\sum\limits_\boldsymbol{y}p(\boldsymbol{x},\boldsymbol{y}|\boldsymbol{\lambda})\<br>&amp;=\sum\limits_\boldsymbol{y}p(\boldsymbol{x}|\boldsymbol{y},\boldsymbol{\lambda})p(\boldsymbol{y}|\boldsymbol{\lambda})\<br>&amp;=\sum\limits_{y_1,y_2,y_3,…,y_T}\pi_{y_1}b_{y_1x_1}a_{y_1y_2}b_{y_2x_2}a_{y_2y_3}b_{y_3x_3}…a_{y_{T-1}y_T}b_{y_Tx_T}<br>\end{aligned}$$</p>
<p>利用这个公式计算量很大，复杂度是$O(TN^T)$，在实际中是不可行的。</p>
<h2 id="2-2-前向算法"><a href="#2-2-前向算法" class="headerlink" title="2.2 前向算法"></a>2.2 前向算法</h2><p>首先需要定义<strong>前向概率</strong>：给定HMM模型$\boldsymbol{\lambda}$，定义时刻$t$部分观测序列为$\boldsymbol{x}=(x_1,x_2,x_3,…,x_t)$且状态为$q_i$的概率为<strong>前向概率</strong>，记作：<br>$$\alpha_t(i)=p(x_1,x_2,x_3,…,x_t,y_t=q_i|\boldsymbol{\lambda})$$</p>
<p><strong>前向算法</strong>：</p>
<ul>
<li><p>输入：HMM模型参数$\boldsymbol{\lambda}$，观测序列$\boldsymbol{x}=(x_1,x_2,x_3,…,x_t)$；</p>
</li>
<li><p>输出：观测序列概率$p(\boldsymbol{x}|\boldsymbol{\lambda})$。</p>
<p>算法步骤：</p>
<ol>
<li>初始：<br>根据$\boldsymbol{\pi}$生成$t=1$时刻的状态$y_1=q_i$，概率为$\pi_i$，并且根据<strong>发射概率矩阵</strong>$\boldsymbol{B}$由$y_1=q_i$生成$x_1$，概率为$b_{ix_1}$，则：<br>$$\alpha_1(i)=\pi_ib_{ix_1}$$</li>
</ol>
</li>
</ul>
<ol start="2">
<li>递推：<br>当$t=2$时，根据<strong>状态转移概率矩阵</strong>$\boldsymbol{A}$，系统的状态由$y_1=q_j$变为$y_2=q_i$，概率为$a_{ji}$，$p(y_2=q_i,y_1=q_j,x_1|\boldsymbol{\lambda})=\alpha_1(j)a_{ji}$。不管$y_1$为什么状态，都可能转移到状态$y_2=q_i$，所以需要对$y_1$求和:$\sum\limits_{j=1}^N\alpha_1(j)a_{ji}$。根据$\alpha_t(i)$的定义，$t=2$时刻，由状态$y_2=q_i$产生观测值$x_2$的概率为$b_{ix_2}$，所以：<br>$$\alpha_2(i)=[\sum\limits_{j=1}^N\alpha_1(j)a_{ji}]b_{ix_2}$$</li>
</ol>
<p>对$t=1,2,3,…T-1$，有：<br>$$\alpha_{t+1}(i)=[\sum\limits^N_{j=1}\alpha_t(j)a_{ji}]b_{ix_{t+1}},\quad i=1,2,3,…N$$<br><img src="https://img-blog.csdnimg.cn/20200318090901998.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0VsZW5zdG9uZQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<ol start="3">
<li>终止：<br> 时刻$t=T$：<br> 根据定义可知：$\alpha_T(i)$表示，$t=T$时刻，处于状态$y_T=q_i$，并且观察到的序列为$\boldsymbol{x}=(x_1,x_2,x_3,…,x_T)$的概率：<br> $$\begin{aligned}<br> \alpha_T(i)&amp;=p(x_1,x_2,x_3,…,x_T,y_T=q_i|\boldsymbol{\lambda})\<br> &amp;=p(\boldsymbol{x},y_T=q_i|\boldsymbol{\lambda})<br> \end{aligned}$$</li>
</ol>
<p>所以：</p>
<p>$$p(\boldsymbol{x}|\boldsymbol{\lambda})=\sum\limits^N_{i=1}\alpha_T(i)$$</p>
<p>前向算法实际是基于“状态序列的路径结构”递推计算$p(\boldsymbol{x}|\boldsymbol{\lambda})$的算法。前向算法高效的关键是其局部计算前向概率，然后利用路径结构将前向概率递推到全局，得到$p(\boldsymbol{x}|\boldsymbol{\lambda})$。在$t=1$时刻计算$\alpha_1(i)$的$N$个值，而当$t\geq2$时，计算每一个\alpha_t(i)的值都会利用前$N$个$\alpha_{t-1}(i)$的值，减少计算量的原因在于每一次计算都直接引用前一个时刻的计算结果，避免了概率的重复计算，复杂度为$O(N<em>N</em>T)$，而不是直接算法的$O(TN^T)$。</p>
<p>例：上文中的盒子和球模型，状态集合为$Q=\{1,2,3\}$，观测集合为$V=\{红，白\}$，<br>$A=\begin{bmatrix}<br>0.5 &amp; 0.2 &amp; 0.3\<br>0.3 &amp; 0.5 &amp; 0.2\<br>0.2 &amp; 0.3 &amp; 0.5<br>\end{bmatrix}$ ，  $B=\begin{bmatrix}<br>0.5 &amp; 0.5 \<br>0.4 &amp; 0.6\<br>0.7 &amp; 0.3<br>\end{bmatrix}$ ， $\pi=(0.2,0.4,0.4)^T$<br>设$T=3$，$\boldsymbol{x}=(红，白，红)$，用前向算法来计算$p(\boldsymbol{x}|\boldsymbol{\lambda})$。<br>解：</p>
<ol>
<li>计算初值：<br> $$\alpha_1(1)=\pi_1b_{1x_1}=0.2\times0.5=0.10$$</li>
</ol>
<p>$$\alpha_1(2)=\pi_2b_{2x_1}=0.4\times0.4=0.16$$</p>
<p>$$\alpha_1(3)=\pi_3b_{3x_1}=0.4\times0.7=0.28$$</p>
<ol start="2">
<li>递推计算：<br> $$\alpha_2(1)=[\sum\limits_{i=1}^3\alpha_1(i)a_{i1}]b_{1x_2}=[0.10\times0.5+0.16\times0.3+0.28\times0.2)]\times0.5=0.077$$</li>
</ol>
<p>$$\alpha_2(2)=[\sum\limits_{i=1}^3\alpha_1(i)a_{i2}]b_{2x_2}=[0.10\times0.2+0.16\times0.5+0.28\times0.3)]\times0.5=0.1104$$</p>
<p>$$\alpha_2(3)=[\sum\limits_{i=1}^3\alpha_1(i)a_{i3}]b_{3x_2}=[0.10\times0.3+0.16\times0.2+0.28\times0.5)]\times0.5=0.0606$$</p>
<p>$$\alpha_3(1)=[\sum\limits_{i=1}^3\alpha_2(i)a_{i1}]b_{1x_3}=0.04187$$</p>
<p>$$\alpha_3(2)=[\sum\limits_{i=1}^3\alpha_2(i)a_{i2}]b_{2x_3}=0.03551$$</p>
<p>$$\alpha_3(3)=[\sum\limits_{i=1}^3\alpha_2(i)a_{i3}]b_{3x_3}=0.05284$$</p>
<ol start="3">
<li>终止： </li>
</ol>
<p>$$p(\boldsymbol{x}|\boldsymbol{\lambda})=\sum\limits_{i=1}^3\alpha_3(i)=0.13022$$</p>
<h2 id="2-3-后向算法"><a href="#2-3-后向算法" class="headerlink" title="2.3 后向算法"></a>2.3 后向算法</h2><p>类似前向算法，定义：给定HMM模型$\boldsymbol{\lambda}$，定义时刻$t$状态为$q_i$的条件下，从$t+1到T$的部分观测序列为$x_{t+1},x_{t+2},x_{t+3},…,x_T$的概率为<strong>后向概率</strong>，记作：<br>$$\beta_t(i)=p(x_{t+1},x_{t+2},x_{t+3},…,x_T|y_t=q_i,\boldsymbol{\lambda})$$<br>后向算法：</p>
<ul>
<li><p>输入：HMM模型参数$\boldsymbol{\lambda}$，观测序列$\boldsymbol{x}=(x_1,x_2,x_3,…,x_t)$；</p>
</li>
<li><p>输出：观测序列概率$p(\boldsymbol{x}|\boldsymbol{\lambda})$。</p>
<ol>
<li><strong>当$t=T$时</strong>:<br>$$\beta_T(i)=p(这里没东西|y_T=q_i,\boldsymbol{\lambda})=1$$<br>这里可以这么理解：按理说好需要看看T时刻过后是什么观测值，但是T时刻之后没有观测值了，不管T时刻状态是什么，之后就是没有观测值，所以没有观测值的概率为1，且与状态无关。</li>
</ol>
</li>
</ul>
<ol start="2">
<li><strong>对$t=T-1$</strong>:<br>已知$\beta_T(j)$，根据HMM模型可知，$y_T=q_j$是由$y_{T-1}$转移而来的，假设$y_{T-1}=q_i$，转移的概率为$a_{ij}$:<br>根据$\beta_{T-1}(i)$的定义，时刻$T-1$的状态$y_{T-1}=q_i$，从T到T的观测序列为$x_T$，T时刻状态$y_T=q_j$生成$x_T$的概率为$b_{jx_T}$，则：<br>$$\beta_{T-1}(i)=\sum\limits^N_{j=1}a_{ij}b_{jx_T}\beta_T(j)$$<br>对$t=T-1,T-2,…,1$:<br>$$b_{jx_t}=p(x_t|y_t=q_j,\boldsymbol{\lambda}))$$</li>
</ol>
<p>$$a_{ij}=p(y_{t+1}=q_j|y_t=q_i,\boldsymbol{\lambda}))$$</p>
<p>$$\beta_{t+1}(j)=p(x_{t+2},x_{t+3},…,x_T|y_{t+1}=q_j,\boldsymbol{\lambda})$$</p>
<p>由状态$y_{t+1}=q_j$生成$t+1$时刻的观测值$x_{t+1}$:<br>$$\begin{aligned}<br>b_{jx_{t+1}}\beta_{t+1}(j)&amp;=p(x_{t+1}|y_{t+1}=q_j,\boldsymbol{\lambda})p(x_{t+2},x_{t+3},…,x_T|y_{t+1}=q_j,\boldsymbol{\lambda})\<br>&amp;=p(x_{t+1},x_{t+2},…,x_T|y_{t+1}=q_j,\boldsymbol{\lambda})\end{aligned}$$</p>
<p>按照条件概率来理解：在$t+1$时刻状态为$y_{t+1}=q_j$的条件下，观察到$x_{t+1},x_{t+2},…,x_T$的概率为$b_{jx_{t+1}}\beta_{t+1}(j)$，由于$\beta_t(i)$与$t$时刻的状态$y_t$有关，根据HMM模型的第一个假设，$y_{t+1}$仅仅与$y_t$有关，且概率$a_{ij}$由状态转移矩阵矩阵A提供。$\beta_t(i)$表示在$t$时刻状态为$y_t=q_i$的条件下，观察到$x_{t+1},x_{t+2},…,x_T$的概率，这个概率若要用$\beta_{t+1}(j)$来表示，针对每一个$y_{t+1}=q_j$，都要乘以从$y_t=q_i$到$y_{t+1}=q_j$的状态转移概率$a_{ij}$，$y_{t+1}$一共有N种状态，所以：<br>$$\begin{aligned}<br>a_{ij}b_{jx_{t+1}}\beta_{t+1}(j)&amp;=p(x_{t+1},x_{t+2},…,x_T|y_{t+1}=q_j,\boldsymbol{\lambda})a_{ij}\<br>&amp;=p(x_{t+1},x_{t+2},…,x_T|y_{t+1}=q_j,\boldsymbol{\lambda})p(y_{t+1}=q_j|y_t=q_i,\boldsymbol{\lambda}))\<br>&amp;=p(x_{t+1},x_{t+2},…,x_T,y_{t+1}=q_j,|y_t=q_i,\boldsymbol{\lambda})<br>\end{aligned}$$</p>
<p>$$\begin{aligned}\beta_t(i)&amp;=p(x_{t+1},x_{t+2},…,x_T|y_t=q_i,\boldsymbol{\lambda})\<br>&amp;=\sum\limits_{y_{t+1}}p(x_{t+1},x_{t+2},…,x_T,y_{t+1}=q_j,|y_t=q_i,\boldsymbol{\lambda})\<br>&amp;=\sum\limits_{j=1}^Na_{ij}b_{jx_{t+1}}\beta_{t+1}(j)<br>\end{aligned}$$<br>所以：<br>$$\beta_t(i)=\sum\limits_{j=1}^Na_{ij}b_{jx_{t+1}}\beta_{t+1}(j),\quad i=1,2,3,…,N$$<br><img src="https://img-blog.csdnimg.cn/20200318090609546.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0VsZW5zdG9uZQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<ol start="3">
<li><strong>当$t=1$时</strong>，$\beta_1(i)=p(x_2,x_3,x_4,…,x_T|y_1=q_i,\boldsymbol{\lambda})$；按照步骤2的思想，针对$t=1$时刻的每一种状态$y_1=q_i$，都需要乘上初始状态概率向量和相应的发射概率矩阵。<br> $$p(\boldsymbol{x}|\boldsymbol{\lambda})=\sum\limits_{i=1}^N\pi_ib_{ix_1}\beta_{t+1}(i)$$</li>
</ol>
<h2 id="2-4-一些概率与期望值的计算"><a href="#2-4-一些概率与期望值的计算" class="headerlink" title="2.4 一些概率与期望值的计算"></a>2.4 一些概率与期望值的计算</h2><p>利用前向概率和后向概率，可以得到关于单个状态和两个状态概率的计算公式。</p>
<ol>
<li>给定模型$\boldsymbol{\lambda}$和观测$\boldsymbol{x}$，在时刻$t$处于状态$q_i$的概率，记作$\gamma_t(i)$：<br> $$\gamma_t(i)=p(y_t=q_i|\boldsymbol{x},\boldsymbol{\lambda})$$</li>
</ol>
<p>可以用过前向和后向算法来算：</p>
<p>$$\begin{aligned}<br>\gamma_t(i)=p(y_t=q_i|\boldsymbol{x},\boldsymbol{\lambda})=\frac{p(y_t=q_i,\boldsymbol{x}|\boldsymbol{\lambda})}{p(\boldsymbol{x}|\boldsymbol{\lambda})}<br>\end{aligned}$$</p>
<p>$\alpha_t(i)$定义为时刻$t$部分观测序列为$\boldsymbol{x}=(x_1,x_2,x_3,…,x_t)$且状态为$q_i$的概率，$\beta_t(i)$定义为时刻$t$状态为$q_i$的条件下，从$t+1到T$的部分观测序列为$x_{t+1},x_{t+2},x_{t+3},…,x_T$的概率，则两者相乘表示，观察序列为$\boldsymbol{x}=(x_1,x_2,x_3,…,x_T)$且状态为$q_i$的概率，数学表示为：<br>$$\alpha_t(i)\beta_t(i)=p(y_t=q_i,\boldsymbol{x}|\boldsymbol{\lambda})$$</p>
<p>$$p(\boldsymbol{x}|\boldsymbol{\lambda})=\sum\limits_{y_t}p(y_t=q_i,\boldsymbol{x}|\boldsymbol{\lambda})=\sum\limits_{j=1}^N\alpha_t(i)\beta_t(i)$$</p>
<p>所以：</p>
<p>$$\gamma_t(i)=\frac{\alpha_t(i)\beta_t(i)}{p(\boldsymbol{x}|\boldsymbol{\lambda})}=\frac{\alpha_t(i)\beta_t(i)}{\sum\limits_{j=1}^N\alpha_t(i)\beta_t(i)}$$</p>
<ol start="2">
<li>给定HMM模型参数$\boldsymbol{\lambda}$和观测序列$\boldsymbol{x}$，在时刻$t$处于状态$q_i$且在时刻$t+1$处于状态$q_j$的概率，记作$\xi_t(i,j)$：<br> $$\xi_t(i,j)=p(y_t=q_i,y_{t+1}=q_j|\boldsymbol{x},\boldsymbol{\lambda})$$</li>
</ol>
<p>使用前向和后向算法来计算：<br>$$\begin{aligned}<br>\xi_t(i,j)&amp;=p(y_t=q_i,y_{t+1}=q_j|\boldsymbol{x},\boldsymbol{\lambda})\<br>&amp;=\frac{p(y_t=q_i,y_{t+1}=q_j,\boldsymbol{x}|\boldsymbol{\lambda})}{p(\boldsymbol{x},\boldsymbol{\lambda)}}\<br>&amp;=\frac{p(y_t=q_i,y_{t+1}=q_j,\boldsymbol{x}|\boldsymbol{\lambda})}{\sum\limits_{i=1}^N\sum\limits_{j=1}^Np(y_t=q_i,y_{t+1}=q_j,\boldsymbol{x}|\boldsymbol{\lambda})}<br>\end{aligned}$$</p>
<p>而$p(y_t=q_i,y_{t+1}=q_j,\boldsymbol{x}|\boldsymbol{\lambda})$表示在模型参数下，观测序列$\boldsymbol{x}$以及$t$时刻状态为$q_i$且时刻$t+1$处于状态$q_j$的概率，$\alpha_t(i)=p(y_t=q_i,x_1,x_2,x_3,…,x_t|\boldsymbol{\lambda})$表示在模型参数下，观测序列$x_1,x_2,x_3,…,x_t$以及$t$时刻状态为$q_i$的概率，$\beta_{t+1}(j)=p(x_{t+2},x_{t+3},…,x_T|y_{t+1}=q_j,\boldsymbol{\lambda})$表示在模型参数和$t+1$时刻状态为$q_j$的条件下，观察序列为$x_{t+2},x_{t+3},…,x_T$，两者之间差一个从时刻$t到t+1$的状态转移概率以及时刻$t+1$状态$q_j$产生序列$x_{t+1}$的概率：<br>$$\begin{aligned}<br>p(y_t=q_i,y_{t+1}=q_j,\boldsymbol{x}|\boldsymbol{\lambda})&amp;=p(y_t=q_i,x_1,x_2,…,x_t|\boldsymbol{\lambda})p(y_{t+1}|y_t,\boldsymbol{\lambda})\\&amp;\qquad p(x_{t+1}|y_{t+1},\boldsymbol{\lambda})p(x_{t+2},x_{t+3},…,x_T|y_{t+1}=q_j,\boldsymbol{\lambda})\<br>&amp;=\alpha_t(i)a_{ij}b_{jx_{t+1}}\beta_{t+1}(j)<br>\end{aligned}$$</p>
<p>所以：<br>$$\xi_t(i,j)=\frac{\alpha_t(i)a_{ij}b_{jx_{t+1}}\beta_{t+1}(j)}{\sum\limits_{i=1}^N\sum\limits_{j=1}^N\alpha_t(i)a_{ij}b_{jx_{t+1}}\beta_{t+1}(j)}$$</p>
<p>3.将$\xi_t(i,j)$和$\gamma_t(i)$对各个时刻求和，可以得到一些有用的期望值：</p>
<ul>
<li>在观测$\boldsymbol{x}$下，状态$q_i$出现的期望值：$\sum\limits_{t=1}^T\gamma_t(i)$</li>
<li>在观测$\boldsymbol{x}$下,由状态$q_i$转移的期望值：$\sum\limits_{t=1}^{T-1}\gamma_t(i)$</li>
<li>在观测$\boldsymbol{x}$下,由状态$q_i$转移到状态$q_j$的期望值：$\sum\limits_{t=1}^{T-1}\xi_t(i,j)$</li>
</ul>
<h1 id="3-模型训练问题及算法"><a href="#3-模型训练问题及算法" class="headerlink" title="3 模型训练问题及算法"></a>3 模型训练问题及算法</h1><p>给定训练集$(\boldsymbol{x}^{(i)},\boldsymbol{y}^{(i)})$，估计模型参数$\lambda=(\boldsymbol{\pi},A,B)$，使得在该模型下观测序列概率$p(\boldsymbol{x}|\lambda)$最大。根据训练数据是否有状态序列数据分为：完全数据和非完全数据，分别使用监督学习和非监督学习实现。</p>
<h2 id="3-1-监督学习——最大似然估计"><a href="#3-1-监督学习——最大似然估计" class="headerlink" title="3.1 监督学习——最大似然估计"></a>3.1 监督学习——最大似然估计</h2><p>在监督学习中，我们使用极大似然法来估计HMM模型参数。<br>假设给定训练数据包含S个长度相同的观测序列$\{(\boldsymbol{x}^1,\boldsymbol{y}^1),(\boldsymbol{x}^2,\boldsymbol{y}^2),…,(\boldsymbol{x}^S,\boldsymbol{y}^S)\}$，使用极大似然法来估计HMM模型参数。</p>
<p><strong>初始状态概率向量的估计</strong>：<br>统计S个样本中，初始状态为$q_i$的频率。<br>$$\hat{\pi}_i=\frac{N_{q_i}}{S}$$<br>其中，$N_{q_i}$是初始状态为$q_i$的样本数量，S是样本的数量。</p>
<p><strong>状态转移概率矩阵的估计</strong>：<br>设样本中时刻t处于状态$q_i$，时刻t+1处于状态$q_j$的频数为$A_{ij}$，那么状态转移概率矩阵的估计为：<br>$$\hat{a}_{ij}=\frac{A_{ij}}{\sum\limits_{j=1}^NA_{ij}},\quad j=1,2,3,…,N;\quad i=1,2,3,…,N$$</p>
<p><strong>发射概率矩阵的估计</strong>：<br>设样本中状态为$i$并观测值为$j$的频数$B_{ij}$，那么状态为$i$观测为$j$的概率$b_{ij}$的估计为：<br>$$\hat{b}_{ij}=\frac{B_{ij}}{\sum\limits_{j=1}^MB_{ij}},\quad j=1,2,3,…,M;\quad i=1,2,3,…,N$$</p>
<p><strong>监督学习的方法就是拿频率来估计概率</strong>。</p>
<h2 id="3-2-非监督学习——EM算法"><a href="#3-2-非监督学习——EM算法" class="headerlink" title="3.2 非监督学习——EM算法"></a>3.2 非监督学习——EM算法</h2><p>假设给定训练数据只包含S个长度为T的观测序列$\boldsymbol{x}=\{\boldsymbol{x}^1,\boldsymbol{x}^2,,…,\boldsymbol{x}^S\}$而没有对应的状态序列，目标是学习HMM模型的参数$\boldsymbol{\lambda}=(\boldsymbol{\pi},A,B)$。将状态序列看作不可观测的隐数据$\boldsymbol{Y}$，HMM模型事实上是一个含有隐变量的概率模型：<br>$$p(\boldsymbol{X}|\boldsymbol{\lambda})=\sum\limits_\boldsymbol{Y}p(\boldsymbol{X}|\boldsymbol{Y},\boldsymbol{\lambda})p(\boldsymbol{Y}|\boldsymbol{\lambda})$$<br>这个参数可以由<strong>EM算法</strong>实现。</p>
<ol>
<li><p><strong>确定数据的对数似然函数</strong><br> 所有观测数据写成$\boldsymbol{x}=\{x_1,x_2,x_3,…,x_T\}$，所有的隐藏状态数据写成$\boldsymbol{y}=\{y_1,y_2,,…,y_T\}$，则完全数据是$(\boldsymbol{x},\boldsymbol{y})=(x_1,x_2,x_3,…,x_T,y_1,y_2,,…,y_T)$，完全数据的对数似然函数是$\log{p(\boldsymbol{x},\boldsymbol{y}|\boldsymbol{\lambda})}$。</p>
</li>
<li><p><strong>Em算法的E步</strong>：求Q函数$$\begin{aligned}<br> Q(\boldsymbol{\lambda},\overline{\boldsymbol{\lambda}})&amp;=E_\boldsymbol{y}[\log{p(\boldsymbol{y},\boldsymbol{y}|\boldsymbol{\lambda})}|\boldsymbol{x},\overline{\boldsymbol{\lambda}}]\<br> &amp;=\sum\limits_\boldsymbol{y}\log{p(\boldsymbol{x},\boldsymbol{y}|\boldsymbol{\lambda})}p(\boldsymbol{x},\boldsymbol{y}|\overline{\boldsymbol{\lambda}})<br> \end{aligned}$$</p>
</li>
</ol>
<p>其中$\overline{\boldsymbol{\lambda}}$是HMM模型参数的当前估计值，$\boldsymbol{\lambda}$是要极大化的HMM模型参数。<br>$$p(\boldsymbol{x},\boldsymbol{y}|\boldsymbol{\lambda})=\pi_{y_1}b_{y_1x_1}a_{y_1y_2}b_{y_2x_2}\cdot …\cdot a_{y_{T-1}y_T}b_{y_Tx_T}$$<br>所以:<br>$Q(\boldsymbol{\lambda},\overline{\boldsymbol{\lambda}})=\sum\limits_\boldsymbol{y}\log{\pi_{y_1}p(\boldsymbol{x},\boldsymbol{y}|\overline{\boldsymbol{\lambda}}})+\sum\limits_\boldsymbol{y}[\sum\limits^{T-1}_{t=1}\log{a_{y_ty_{t+1}}]p(\boldsymbol{x},\boldsymbol{y}|\overline{\boldsymbol{\lambda}}})+\sum\limits_\boldsymbol{y}[\sum\limits_{t=1}^T\log{b_{y_tx_t}]p(\boldsymbol{x},\boldsymbol{y}|\overline{\boldsymbol{\lambda}}})$</p>
<ol start="3">
<li><strong>EM算法的M步</strong>：极大化Q函数求模型的参数<br> <strong>第一项：</strong><br> $$\sum\limits_\boldsymbol{y}\log{\pi_{y_1}p(\boldsymbol{x},\boldsymbol{y}|\overline{\boldsymbol{\lambda}}})=\sum\limits_{i=1}^N\log{\pi_ip(\boldsymbol{x},y_1=q_i|\overline{\boldsymbol{\lambda}})}$$<br> 注意到$\sum\limits^{N}_{i=1}{\pi_i}=1$，利用拉格朗日乘子法，写出拉格朗日函数：</li>
</ol>
<p>$$\sum\limits_{i=1}^N\log{\pi_ip(\boldsymbol{x},y_1=q_i|\overline{\boldsymbol{\lambda}})}+\gamma(\sum\limits^{N}_{i=1}-1)$$</p>
<p>求偏导并令其等于0：</p>
<p>$$\frac{\partial}{\partial \pi_i}[\sum\limits_{i=1}^N\log{\pi_ip(\boldsymbol{x},y_1=q_i|\overline{\boldsymbol{\lambda}})}+\gamma(\sum\limits^{N}_{i=1}-1)]=0$$</p>
<p>得到：</p>
<p>$$p(\boldsymbol{x},y_1=q_i|\overline{\boldsymbol{\lambda}})+\gamma\pi_i=0$$</p>
<p>对i求和：<br>$$\gamma=-p(\boldsymbol{x}|\overline{\boldsymbol{\lambda}})$$</p>
<p>所以，得到$\pi_i$：</p>
<p>$$\pi_i=\frac{p(\boldsymbol{x},y_1=q_i|\overline{\boldsymbol{\lambda}})}{p(\boldsymbol{x}|\overline{\boldsymbol{\lambda}})}$$</p>
<p><strong>第二项：</strong><br>$$\sum\limits_\boldsymbol{y}[\sum\limits^{T-1}_{t=1}\log{a_{y_ty_{t+1}}]p(\boldsymbol{x},\boldsymbol{y}|\overline{\boldsymbol{\lambda}}})=\sum\limits_{i=1}^N\sum\limits_{j=1}^N\sum\limits_{t=1}^{T-1}\log{a_{ij}p(\boldsymbol{x},y_t=q_i,y_{t+1}=q_j|\overline{\boldsymbol{\lambda}})}$$</p>
<p>类似第一项，应用$\sum\limits_{j=1}^N=1$的拉格朗日乘子法可以求出：<br>$$a_{ij}=\frac{\sum\limits_{t=1}^{T-1}p(\boldsymbol{x},y_t=q_i,y_{t+1}=q_j|\overline{\boldsymbol{\lambda}})}{\sum\limits_{t=1}^{T-1}p(\boldsymbol{x},y_t=q_i|\overline{\boldsymbol{\lambda}})}$$</p>
<p><strong>第三项：</strong><br>$$\sum\limits_\boldsymbol{y}[\sum\limits_{t=1}^T\log{b_{y_tx_t}]p(\boldsymbol{x},\boldsymbol{y}|\overline{\boldsymbol{\lambda}}})=\sum\limits_{j=1}^N\sum\limits_{t=1}^{T}\log{b_{jx_t}p(\boldsymbol{x},y_t=q_j|\overline{\boldsymbol{\lambda}})}$$</p>
<p>同样使用拉格朗日乘子法，求得：<br>$$b_{jk}=\frac{\sum\limits_{t=1}^Tp(\boldsymbol{x},y_t=q_j|\overline{\boldsymbol{\lambda}})I(x_t=v_k)}{\sum\limits_{t=1}^Tp(\boldsymbol{x},y_t=q_j|\overline{\boldsymbol{\lambda}})}$$</p>
<h2 id="3-3-Baum-Welch算法"><a href="#3-3-Baum-Welch算法" class="headerlink" title="3.3 Baum-Welch算法"></a>3.3 Baum-Welch算法</h2><p>将EM算法的参数式子分别用前向和后向概率算出的$\gamma_t(i),\xi_t(i,j)$表示则:<br>$$a_{ij}=\frac{\sum\limits_{t=1}^{T-1}\xi_t(i,j)}{\sum\limits_{t=1}^{T-1}\gamma_t(i)}$$</p>
<p>$$b_{ij}=\frac{\sum\limits_{t=1,x_t=v_j}^T\gamma_t(i)}{\sum\limits_{t=1}^T\gamma_t(i)}$$</p>
<p>$$\pi_i=\gamma_1(i)$$</p>
<h1 id="4-序列预测问题及算法"><a href="#4-序列预测问题及算法" class="headerlink" title="4 序列预测问题及算法"></a>4 序列预测问题及算法</h1><p>序列预测问题就是已知模型参数$\lambda=(\boldsymbol{\pi},A,B)$，给定观测序列$\boldsymbol{x}$，求最有可能的状态序列$\boldsymbol{y}$，即求$p(\boldsymbol{y}|\boldsymbol{x})$的最大值。一般有两种解法：近似解法与维特比解法。</p>
<h2 id="4-1-近似解法"><a href="#4-1-近似解法" class="headerlink" title="4.1 近似解法"></a>4.1 近似解法</h2><p>近似算法的思想是，在每个时刻$t$选择该时刻最有可能出现的状态$y_t^<em>$，从而得到一个状态序列$\boldsymbol{y}=(y_i^</em>,y_2^<em>,…,y_t^</em>)$，将它作为预测的结果。<br>给定模型$\boldsymbol{\lambda}$和观测$\boldsymbol{x}$，在时刻$t$处于状态$q_i$的概率:<br>$$\gamma_t(i)==\frac{\alpha_t(i)\beta_t(i)}{p(\boldsymbol{x}|\boldsymbol{\lambda})}=\frac{\alpha_t(i)\beta_t(i)}{\sum\limits_{j=1}^N\alpha_t(i)\beta_t(i)}$$</p>
<p>在每一个时刻最有可能的状态$y_t^<em>$是：<br>$$y_t^</em>=\arg\max_{1\leq i\leq N}[\gamma_t(i)],\quad t=1,2,3…,T$$<br>从而得到整个序列。<br>近似算法的优点是计算简单，其缺点是<strong>不能保证预测的状态序列整体是最有可能的状态序列</strong>，因为预测的状态序列可能有<strong>实际不发生</strong>的部分。事实上，上述方法得到的状态序列中有可能存在<strong>转移概率为0的相邻状态</strong>。尽管如此，近似算法仍然是有用的。</p>
<h2 id="4-2-维特比算法（Viterbi-algorithm）"><a href="#4-2-维特比算法（Viterbi-algorithm）" class="headerlink" title="4.2 维特比算法（Viterbi algorithm）"></a>4.2 维特比算法（Viterbi algorithm）</h2><p><strong>维特比算法</strong>实际是用<strong>动态规划</strong>解HMM模型序列预测问题，用动态规划求解概率最大路径（最优路径），一条路径对应一个状态序列。<br>根据图论，假设最优路径为$\boldsymbol{y}^<em>$，其中从起点到时刻$t$的一段最优路径是$(y_1^</em>,y_2^<em>,…,y_t^</em>)$，则这部分路径对于后序最优路径（$y_t^<em>,y_{t+1}^</em>,y_{t+2}^<em>,…,y_T^</em>$）的选取来说一定也是最优的。可以使用反证法来证明：假设存在另一条局部路径$(y_1^,,y_2^,,…,y_t^,)$要优于$(y_1^<em>,y_2^</em>,…,y_t^<em>)$，那么它与（$y_t^</em>,y_{t+1}^<em>,y_{t+2}^</em>,…,y_T^<em>$）拼接起来蝴蝶刀另一条更优的全局最优路径，与定义矛盾。<br>根据HMM模型的第一个假设，$y_{t+1}$仅仅只与$y_t$相关，所以网状图可以动态规划地搜索。<em>*定义</em></em>：二维数组$\delta_t(i)$表示在时刻$t$以$q_j$结尾的所有局部路径的最大概率。从第一步推到第T步，每次递推都在上一次的N条局部路径中挑选，所以复杂度为$O(TN)$。为了得到路径，还需要定义一个二维数组$\psi_t(i)$，记录每个状态的前驱。</p>
<p>$$\delta_t(i)=\max_{y_1,y_2,…,y_{t-1}}p(y_t=q_i,y_{t-1},…y_1,x_t,x_{t-1},…,x_1|\boldsymbol{\lambda})$$</p>
<p>$$\psi_t(i)=\arg\max_{1\leq j \leq N}[\delta_{t-1}(j)a_{ji}]$$</p>
<p>维特比算法：</p>
<ol>
<li><strong>初始化</strong>，当$t=1$时，最优路径的备选由N个状态组成，它的前驱为空：<br> $$\delta_1(i)=\pi_ib_{ix_1},\quad i=1,2,3,..,N$$</li>
</ol>
<p>$$\psi_1(i)=0,\quad i=1,2,3,..,N$$</p>
<ol start="2">
<li><strong>递推</strong>，当$t\geq 2$时，每条备选的路径像贪吃蛇一样吃入一个状态，长度增加一个单位，根据状态转移概率和发射概率计算<strong>花费</strong>。找出新的局部最优路径，更新两个数组。<br> $$\delta_t(i)=\max_{1\leq j \leq N}[\delta_{t-1}(j)a_{ji}]b_{ix_t},\quad i=1,2,3,..,N$$</li>
</ol>
<p>$$\psi_t(i)=\arg\max_{1\leq j \leq N}(\delta_t(j)a_{ji}),\quad i=1,2,3,..,N$$</p>
<ol start="3">
<li><strong>终止</strong>，找出最终时刻$(\delta_t(i)$数组中最大概率$p^<em>$，以及相应的结尾状态下表$y_T^</em>$<br> $$P^*=\max_{1\leq j \leq N}\delta_T(i)$$</li>
</ol>
<p>$$y_T^*=\arg\max_{1\leq j \leq N}\delta_T(i)$$</p>
<ol start="4">
<li>回溯，根据前驱数组$\psi_t$回溯前驱状态，取得最优路径状态下标$\boldsymbol{y}^<em>=(y_1^</em>,y_2^<em>,…,y_T^</em>)$。<br> $$y_t^<em>=\psi_{t+1}(y_{t+1}^</em>),\quad t=T-1,T-2,…,1$$</li>
</ol>
<p>举个例子：<br>上文中的盒子和球模型，状态集合为$Q=\{1,2,3\}$，观测集合为$V=\{红，白\}$，<br>$A=\begin{bmatrix}<br>0.5 &amp; 0.2 &amp; 0.3\<br>0.3 &amp; 0.5 &amp; 0.2\<br>0.2 &amp; 0.3 &amp; 0.5<br>\end{bmatrix}$ ，  $B=\begin{bmatrix}<br>0.5 &amp; 0.5 \<br>0.4 &amp; 0.6\<br>0.7 &amp; 0.3<br>\end{bmatrix}$ ， $\pi=(0.2,0.4,0.4)^T$<br>设$T=3$，$\boldsymbol{x}=(红，白，红)$，求最优状态序列，即最优路径$\boldsymbol{y}^<em>=(y_1^</em>,y_2^<em>,…,y_T^</em>)$。<br>解：</p>
<ol>
<li>初始化，在$t=1$时，对每一个状态$q_i，i=1,2,3$，求状态为$q_i$观测为$x_1$为红的概率，记此概率为$\delta_1(i)$。<br> $$\delta_1(i)=\pi_ib_{ix_1}=\pi_ib_{i红}，\quad i=1,2,3$$</li>
</ol>
<p>$$\delta_1(1)=0.2\times0.5=0.1,\delta_1(2)=0.4\times0.4=0.16,\delta_1(3)=0.4\times0.7=0.28$$</p>
<p>$$\psi_1(i)=0,\quad i=1,2,3$$</p>
<ol start="2">
<li>在$t=2$时，对每个状态$i，i=1,2,3$:<br> $$\delta_2(i)=\max_{1\leq j \leq 3}[\delta_{1}(j)a_{ji}]b_{i白},\quad i=1,2,3,..,N$$</li>
</ol>
<p>$$\begin{aligned}<br>\delta_2(1)&amp;=\max_{1\leq j \leq 3}[\delta_{1}(j)a_{ji}]b_{i白}\<br>&amp;=\max_j\{o.1\times0.5,0.16\times0.3,0.28\times0.2\}\times0.5\<br>&amp;=0.028<br>\end{aligned}$$</p>
<p>$$\psi_2(1)=3$$</p>
<p>同理：</p>
<p>$$\delta_2(2)=0.0504,\quad\psi_2(3)=3$$</p>
<p>$$\delta_2(3)=0.042,\quad\psi_2(3)=3$$</p>
<p>同样，$t=3$：</p>
<p>$$\delta_3(1)=0.00756,\quad\psi_3(1)=2$$</p>
<p>$$\delta_3(2)=0.01008,\quad\psi_3(2)=2$$</p>
<p>$$\delta_3(3)=0.0417,\quad\psi_3(3)=3$$</p>
<ol start="3">
<li>最优路径概率:<br> $$P^*=\max_{1\leq i\leq 3}\delta_3(i)=0.0147$$</li>
</ol>
<p>$$y_3^*=\arg\max_{1\leq j \leq 3}\delta_3(i)=3$$</p>
<ol start="4">
<li>回溯：<br> $$t=2,\quad y_2^<em>=\psi_3(y_3^</em>)=\psi_3(3)=3$$</li>
</ol>
<p>$$t=1,\quad y_1^<em>=\psi_2(y_2^</em>)=\psi_2(3)=3$$</p>
<p>所以，最优路径为$\boldsymbol{y}^<em>=(y_1^</em>,y_2^<em>,y_3^</em>)=(3,3,3)$。</p>
<h1 id="5-hmmlearn使用"><a href="#5-hmmlearn使用" class="headerlink" title="5 hmmlearn使用"></a>5 hmmlearn使用</h1><p><a href="https://hmmlearn.readthedocs.io/en/latest/index.html" target="_blank" rel="noopener">hmmlearn</a>是一个实现了hmm的python库，安装很简单，使用<code>pip install hmmlearn</code>就行。<br>hmmlearn实现了三种HMM模型，分成两类：</p>
<ul>
<li>针对观测状态是连续的：GaussianHMM和GMMHMM（广泛用于语音识别）</li>
<li>针对观测状态是离散的：MultinomialHMM，也就是上文中提到的。</li>
</ul>
<p>对于MultinomialHMM的模型，使用比较简单，”startprob_”参数对应我们的初始状态概率向量$\pi$， “transmat_”对应我们的状态转移矩阵$A$, “emissionprob_”对应我们的发射概率矩阵$B$。</p>
<p>对于连续观测状态的HMM模型，GaussianHMM类假设观测状态符合高斯分布，而GMMHMM类则假设观测状态符合混合高斯分布。一般情况下我们使用GaussianHMM即高斯分布的观测状态即可。以下对于连续观测状态的HMM模型，我们只讨论GaussianHMM类。</p>
<p>在GaussianHMM类中，”startprob_”参数对应我们的隐藏状态初始分布$\pi$ , “transmat_”对应我们的状态转移矩阵A, 比较特殊的是发射概率的表示方法，此时由于观测状态是连续值，我们无法像MultinomialHMM一样直接给出矩阵B。而是采用给出各个隐藏状态对应的观测状态高斯分布的概率密度函数的参数。</p>
<p>如果观测序列是一维的，则观测状态的概率密度函数是一维的普通高斯分布。如果观测序列是<br>N维的，则隐藏状态对应的观测状态的概率密度函数是N维高斯分布。高斯分布的概率密度函数参数可以用μ表示高斯分布的期望向量，Σ表示高斯分布的协方差矩阵。在GaussianHMM类中，“means”用来表示各个隐藏状态对应的高斯分布期望向量μ形成的矩阵，而“covars”用来表示各个隐藏状态对应的高斯分布协方差矩阵Σ形成的三维张量。</p>
<p>参考：<a href="https://blog.csdn.net/tostq/article/details/70851531?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">深度剖析HMM</a></p>
<h2 id="5-1-pythonceshi工具unnitest"><a href="#5-1-pythonceshi工具unnitest" class="headerlink" title="5.1 pythonceshi工具unnitest"></a>5.1 pythonceshi工具unnitest</h2><p>测试工具unnitest非常容易使用，首先是建立一个继承自TestCase的测试类，然后通过覆盖setUp()完成相关初始化，最后通过覆盖tearDown()方法清除测试中产生的数据，为以后的TestCase留下一个干净的环境。我们需要在测试类中编写以test_开头的测试函数，unnitest会在测试中自动执行以test_开头的测试函数，unnitest的使用框架：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> unittest  

<span class="token keyword">class</span> <span class="token class-name">XXXXX</span><span class="token punctuation">(</span>unittest<span class="token punctuation">.</span>TestCase<span class="token punctuation">)</span><span class="token punctuation">:</span>  

    <span class="token keyword">def</span> <span class="token function">setUp</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>  
    <span class="token comment" spellcheck="true"># 自行编写</span>
    <span class="token keyword">pass</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>  
    unittest<span class="token punctuation">.</span>main<span class="token punctuation">(</span><span class="token punctuation">)</span> 
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="5-2-离散HMM测试"><a href="#5-2-离散HMM测试" class="headerlink" title="5.2 离散HMM测试"></a>5.2 离散HMM测试</h2><p>对离散HMM模型的测试代码：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 计算平方误差</span>
<span class="token keyword">def</span> <span class="token function">s_error</span><span class="token punctuation">(</span>A<span class="token punctuation">,</span> B<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> sqrt<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">(</span>A<span class="token operator">-</span>B<span class="token punctuation">)</span><span class="token operator">*</span><span class="token punctuation">(</span>A<span class="token operator">-</span>B<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>B<span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">DiscreteHMM_Test</span><span class="token punctuation">(</span>unittest<span class="token punctuation">.</span>TestCase<span class="token punctuation">)</span><span class="token punctuation">:</span>


    <span class="token keyword">def</span> <span class="token function">setUp</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 建立两个HMM，隐藏状态个数为4，X可能分布为10类</span>
        n_state <span class="token operator">=</span><span class="token number">4</span>
        n_feature <span class="token operator">=</span> <span class="token number">10</span>
        X_length <span class="token operator">=</span> <span class="token number">1000</span>
        n_batch <span class="token operator">=</span> <span class="token number">100</span> <span class="token comment" spellcheck="true"># 批量数目</span>
        self<span class="token punctuation">.</span>n_batch <span class="token operator">=</span> n_batch
        self<span class="token punctuation">.</span>X_length <span class="token operator">=</span> X_length
        self<span class="token punctuation">.</span>test_hmm <span class="token operator">=</span> hmm<span class="token punctuation">.</span>DiscreteHMM<span class="token punctuation">(</span>n_state<span class="token punctuation">,</span> n_feature<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>comp_hmm <span class="token operator">=</span> ContrastHMM<span class="token punctuation">(</span>n_state<span class="token punctuation">,</span> n_feature<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>X<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Z <span class="token operator">=</span> self<span class="token punctuation">.</span>comp_hmm<span class="token punctuation">.</span>module<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>self<span class="token punctuation">.</span>X_length<span class="token operator">*</span><span class="token number">10</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>test_hmm<span class="token punctuation">.</span>train<span class="token punctuation">(</span>self<span class="token punctuation">.</span>X<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Z<span class="token punctuation">)</span>


    <span class="token keyword">def</span> <span class="token function">test_train_batch</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        X <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        Z <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> b <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>n_batch<span class="token punctuation">)</span><span class="token punctuation">:</span>
            b_X<span class="token punctuation">,</span> b_Z <span class="token operator">=</span> self<span class="token punctuation">.</span>comp_hmm<span class="token punctuation">.</span>module<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>self<span class="token punctuation">.</span>X_length<span class="token punctuation">)</span>
            X<span class="token punctuation">.</span>append<span class="token punctuation">(</span>b_X<span class="token punctuation">)</span>
            Z<span class="token punctuation">.</span>append<span class="token punctuation">(</span>b_Z<span class="token punctuation">)</span>


        batch_hmm <span class="token operator">=</span> hmm<span class="token punctuation">.</span>DiscreteHMM<span class="token punctuation">(</span>self<span class="token punctuation">.</span>test_hmm<span class="token punctuation">.</span>n_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>test_hmm<span class="token punctuation">.</span>x_num<span class="token punctuation">)</span>
        batch_hmm<span class="token punctuation">.</span>train_batch<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Z<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 判断概率参数是否接近</span>
        <span class="token comment" spellcheck="true"># 初始概率判定没有通过！！！</span>
        self<span class="token punctuation">.</span>assertAlmostEqual<span class="token punctuation">(</span>s_error<span class="token punctuation">(</span>batch_hmm<span class="token punctuation">.</span>start_prob<span class="token punctuation">,</span> self<span class="token punctuation">.</span>comp_hmm<span class="token punctuation">.</span>module<span class="token punctuation">.</span>startprob_<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>assertAlmostEqual<span class="token punctuation">(</span>s_error<span class="token punctuation">(</span>batch_hmm<span class="token punctuation">.</span>transmat_prob<span class="token punctuation">,</span> self<span class="token punctuation">.</span>comp_hmm<span class="token punctuation">.</span>module<span class="token punctuation">.</span>transmat_<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>assertAlmostEqual<span class="token punctuation">(</span>s_error<span class="token punctuation">(</span>batch_hmm<span class="token punctuation">.</span>emission_prob<span class="token punctuation">,</span> self<span class="token punctuation">.</span>comp_hmm<span class="token punctuation">.</span>module<span class="token punctuation">.</span>emissionprob_<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>


    <span class="token keyword">def</span> <span class="token function">test_train</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 判断概率参数是否接近</span>
        <span class="token comment" spellcheck="true"># 单批量的初始概率一定是不准的</span>
        <span class="token comment" spellcheck="true"># self.assertAlmostEqual(s_error(self.test_hmm.start_prob, self.comp_hmm.module.startprob_), 0, 1)</span>
        self<span class="token punctuation">.</span>assertAlmostEqual<span class="token punctuation">(</span>s_error<span class="token punctuation">(</span>self<span class="token punctuation">.</span>test_hmm<span class="token punctuation">.</span>transmat_prob<span class="token punctuation">,</span> self<span class="token punctuation">.</span>comp_hmm<span class="token punctuation">.</span>module<span class="token punctuation">.</span>transmat_<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>assertAlmostEqual<span class="token punctuation">(</span>s_error<span class="token punctuation">(</span>self<span class="token punctuation">.</span>test_hmm<span class="token punctuation">.</span>emission_prob<span class="token punctuation">,</span> self<span class="token punctuation">.</span>comp_hmm<span class="token punctuation">.</span>module<span class="token punctuation">.</span>emissionprob_<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>


    <span class="token keyword">def</span> <span class="token function">test_X_prob</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        X<span class="token punctuation">,</span>_ <span class="token operator">=</span> self<span class="token punctuation">.</span>comp_hmm<span class="token punctuation">.</span>module<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>self<span class="token punctuation">.</span>X_length<span class="token punctuation">)</span>
        prob_test <span class="token operator">=</span> self<span class="token punctuation">.</span>test_hmm<span class="token punctuation">.</span>X_prob<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        prob_comp <span class="token operator">=</span> self<span class="token punctuation">.</span>comp_hmm<span class="token punctuation">.</span>module<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>assertAlmostEqual<span class="token punctuation">(</span>s_error<span class="token punctuation">(</span>prob_test<span class="token punctuation">,</span> prob_comp<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>


    <span class="token keyword">def</span> <span class="token function">test_predict</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        X<span class="token punctuation">,</span> _ <span class="token operator">=</span> self<span class="token punctuation">.</span>comp_hmm<span class="token punctuation">.</span>module<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>self<span class="token punctuation">.</span>X_length<span class="token punctuation">)</span>
        prob_next <span class="token operator">=</span> self<span class="token punctuation">.</span>test_hmm<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X<span class="token punctuation">,</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>test_hmm<span class="token punctuation">.</span>x_num<span class="token number">-1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>assertEqual<span class="token punctuation">(</span>prob_next<span class="token punctuation">.</span>shape<span class="token punctuation">,</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>test_hmm<span class="token punctuation">.</span>n_state<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


    <span class="token keyword">def</span> <span class="token function">test_decode</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        X<span class="token punctuation">,</span>_ <span class="token operator">=</span> self<span class="token punctuation">.</span>comp_hmm<span class="token punctuation">.</span>module<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>self<span class="token punctuation">.</span>X_length<span class="token punctuation">)</span>
        test_decode <span class="token operator">=</span> self<span class="token punctuation">.</span>test_hmm<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        _<span class="token punctuation">,</span> comp_decode <span class="token operator">=</span> self<span class="token punctuation">.</span>comp_hmm<span class="token punctuation">.</span>module<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>assertAlmostEqual<span class="token punctuation">(</span>s_error<span class="token punctuation">(</span>test_decode<span class="token punctuation">,</span> comp_decode<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    unittest<span class="token punctuation">.</span>main<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="5-3-HMM测试"><a href="#5-3-HMM测试" class="headerlink" title="5.3 HMM测试"></a>5.3 HMM测试</h2><p>利用hmmlearn初始化一个高斯模型</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">ContrastHMM</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_state<span class="token punctuation">,</span> n_feature<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>module <span class="token operator">=</span> hmmlearn<span class="token punctuation">.</span>hmm<span class="token punctuation">.</span>GaussianHMM<span class="token punctuation">(</span>n_components<span class="token operator">=</span>n_state<span class="token punctuation">,</span>covariance_type<span class="token operator">=</span><span class="token string">"full"</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 初始概率</span>
        self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>startprob_ <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span>n_state<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>startprob_ <span class="token operator">=</span> self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>startprob_ <span class="token operator">/</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>startprob_<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 转换概率</span>
        self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>transmat_ <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">(</span>n_state<span class="token punctuation">,</span>n_state<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>transmat_ <span class="token operator">=</span> self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>transmat_ <span class="token operator">/</span> np<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>transmat_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>n_state<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span>n_state<span class="token punctuation">,</span>n_state<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 高斯发射概率</span>
        self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>means_ <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span>n_state<span class="token punctuation">,</span>n_feature<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">10</span>
        self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>covars_ <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token number">5</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>tile<span class="token punctuation">(</span>np<span class="token punctuation">.</span>identity<span class="token punctuation">(</span>n_feature<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>n_state<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>利用hmmlearn初始化一个离散HMM模型:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">ContrastHMM</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_state<span class="token punctuation">,</span> n_feature<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>module <span class="token operator">=</span> hmmlearn<span class="token punctuation">.</span>hmm<span class="token punctuation">.</span>MultinomialHMM<span class="token punctuation">(</span>n_components<span class="token operator">=</span>n_state<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 初始概率</span>
        self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>startprob_ <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span>n_state<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>startprob_ <span class="token operator">=</span> self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>startprob_ <span class="token operator">/</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>startprob_<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># print self.module.startprob_</span>
        <span class="token comment" spellcheck="true"># 转换概率</span>
        self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>transmat_ <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">(</span>n_state<span class="token punctuation">,</span>n_state<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>transmat_ <span class="token operator">=</span> self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>transmat_ <span class="token operator">/</span> np<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>transmat_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>n_state<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span>n_state<span class="token punctuation">,</span>n_state<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># print self.module.transmat_</span>
        <span class="token comment" spellcheck="true"># 发射概率</span>
        self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>emissionprob_ <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span>n_state<span class="token punctuation">,</span>n_feature<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>emissionprob_ <span class="token operator">=</span> self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>emissionprob_ <span class="token operator">/</span> np<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>self<span class="token punctuation">.</span>module<span class="token punctuation">.</span>emissionprob_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>n_feature<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span>n_state<span class="token punctuation">,</span>n_feature<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># print self.module.emissionprob_</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>代码详情请见我的<a href="https://github.com/CodingMarathon/All_Algorithm/tree/master/HMM/easyhmm" target="_blank" rel="noopener">github</a>，请大家帮忙点个star。<br><img src="https://img-blog.csdnimg.cn/20200318170910751.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0VsZW5zdG9uZQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>

            </div>
            <hr />

            
            <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.88rem;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fa fa-close"></i></a>
            <h4 class="reward-title">写作不易，客官能否打赏一杯奶茶？</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    <div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div>
    
</div>

<script src="/libs/share/js/social-share.min.js"></script>

            

    <div class="reprint" id="reprint-statement">
        <p class="reprint-tip">
            <i class="fa fa-exclamation-triangle"></i>&nbsp;&nbsp;
            <span>转载规则</span>
        </p>
        
            <div class="center-align">
                <a rel="license" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                    <img alt=""
                         style="border-width:0"
                         src="https://i.creativecommons.org/l/by/4.0/88x31.png"/>
                </a>
            </div>
            <br/>
            <span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text"
                  property="dct:title" rel="dct:type">
                    《HMM详解》
                </span> 由
            <a xmlns:cc="http://creativecommons.org/ns#" href="/2020/03/26/hmm/" property="cc:attributionName"
               rel="cc:attributionURL">
                CodingMarathon
            </a> 采用
            <a rel="license" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                知识共享署名 4.0 国际许可协议
            </a>进行许可。
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>


        </div>
    </div>

    
    <link rel="stylesheet" href="/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: 'af79022a0bda1da52424',
        clientSecret: '79c4379ef65f69bbba44291b29a5a219e8518959',
        repo: 'CodingMarathon.github.io',
        owner: 'CodingMarathon',
        admin: "CodingMarathon",
        id: '2020/03/26/hmm/',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    
    <style>
    .valine-card {
        margin: 1.5rem auto;
    }

    .valine-card .card-content {
        padding: 20px 20px 5px 20px;
    }

    #vcomments input[type=text],
    #vcomments input[type=email],
    #vcomments input[type=url],
    #vcomments textarea {
        box-sizing: border-box;
    }

    #vcomments p {
        margin: 2px 2px 10px;
        font-size: 1.05rem;
        line-height: 1.78rem;
    }

    #vcomments blockquote p {
        text-indent: 0.2rem;
    }

    #vcomments a {
        padding: 0 2px;
        color: #42b983;
        font-weight: 500;
        text-decoration: underline;
    }

    #vcomments img {
        max-width: 100%;
        height: auto;
        cursor: pointer;
    }

    #vcomments ol li {
        list-style-type: decimal;
    }

    #vcomments ol,
    ul {
        display: block;
        padding-left: 2em;
        word-spacing: 0.05rem;
    }

    #vcomments ul li,
    ol li {
        display: list-item;
        line-height: 1.8rem;
        font-size: 1rem;
    }

    #vcomments ul li {
        list-style-type: disc;
    }

    #vcomments ul ul li {
        list-style-type: circle;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    #vcomments table, th, td {
        border: 0;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments h1 {
        font-size: 1.85rem;
        font-weight: bold;
        line-height: 2.2rem;
    }

    #vcomments h2 {
        font-size: 1.65rem;
        font-weight: bold;
        line-height: 1.9rem;
    }

    #vcomments h3 {
        font-size: 1.45rem;
        font-weight: bold;
        line-height: 1.7rem;
    }

    #vcomments h4 {
        font-size: 1.25rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    #vcomments h5 {
        font-size: 1.1rem;
        font-weight: bold;
        line-height: 1.4rem;
    }

    #vcomments h6 {
        font-size: 1rem;
        line-height: 1.3rem;
    }

    #vcomments p {
        font-size: 1rem;
        line-height: 1.5rem;
    }

    #vcomments hr {
        margin: 12px 0;
        border: 0;
        border-top: 1px solid #ccc;
    }

    #vcomments blockquote {
        margin: 15px 0;
        border-left: 5px solid #42b983;
        padding: 1rem 0.8rem 0.3rem 0.8rem;
        color: #666;
        background-color: rgba(66, 185, 131, .1);
    }

    #vcomments pre {
        font-family: monospace, monospace;
        padding: 1.2em;
        margin: .5em 0;
        background: #272822;
        overflow: auto;
        border-radius: 0.3em;
        tab-size: 4;
    }

    #vcomments code {
        font-family: monospace, monospace;
        padding: 1px 3px;
        font-size: 0.92rem;
        color: #e96900;
        background-color: #f8f8f8;
        border-radius: 2px;
    }

    #vcomments pre code {
        font-family: monospace, monospace;
        padding: 0;
        color: #e8eaf6;
        background-color: #272822;
    }

    #vcomments pre[class*="language-"] {
        padding: 1.2em;
        margin: .5em 0;
    }

    #vcomments code[class*="language-"],
    pre[class*="language-"] {
        color: #e8eaf6;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }

    #vcomments b,
    strong {
        font-weight: bold;
    }

    #vcomments dfn {
        font-style: italic;
    }

    #vcomments small {
        font-size: 85%;
    }

    #vcomments cite {
        font-style: normal;
    }

    #vcomments mark {
        background-color: #fcf8e3;
        padding: .2em;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }
</style>

<div class="card valine-card" data-aos="fade-up">
    <div id="vcomments" class="card-content"></div>
</div>

<script src="/libs/valine/av-min.js"></script>
<script src="/libs/valine/Valine.min.js"></script>
<!-- <script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script> -->

<script>
    new Valine({
        el: '#vcomments',
        appId: '',
        appKey: '',
        notify: 'false' === 'true',
        verify: 'false' === 'true',
        visitor: 'false' === 'true',
        avatar: 'wavatar',
        pageSize: '10',
        lang: 'zh-cn',
        placeholder: '如果你没有GitHub账号，还可以在这里评论啦！'
    });
</script>

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fa fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2020/03/26/crf/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/17.jpg" class="responsive-img" alt="CRF详解">
                        
                        <span class="card-title">CRF详解</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            0 前言​        条件随机场（conditional random field，CRF）是给定一组输入随机变量条件下另一组输出随机变量的条件概率分布模型，其特点是假设输出随机变量构成马尔科夫随机场。本文主要讨论它在标注问题上的应用，
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="fa fa-clock-o fa-fw icon-date"></i>2020-03-26
                        </span>
                        <span class="publish-author">
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                本篇&nbsp;<i class="fa fa-dot-circle-o"></i>
            </div>
            <div class="card">
                <a href="/2020/03/26/hmm/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/27.jpg" class="responsive-img" alt="HMM详解">
                        
                        <span class="card-title">HMM详解</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            1 隐马尔科夫模型本文主要介绍NLP领域中很重要的一个模型——隐马尔科夫模型（Hidden Markov Model，HMM）。希望读完本文后，大家能够清楚地理解HMM并能够应用到实际中。  
隐马尔科夫模型是结构最简单的动态贝叶斯网（dy
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2020-03-26
                            </span>
                        <span class="publish-author">
                            
                        </span>
                    </div>
                </div>

                
            </div>
        </div>
        
    </div>
</article>
</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: CodingMarathon<br />'
            + '作者: CodingMarathon<br />'
            + '链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () { bodyElement.removeChild(newdiv); }, 200);
    });
</script>

    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fa fa-list"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>

<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>
<!-- 代码语言 -->
<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>
<!-- 代码块复制 -->
<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>
<script type="text/javascript" src="/libs/codeBlock/clipboard.min.js"></script>
<!-- 代码块收缩 -->
<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script> 
<!-- 代码块折行 -->
<style type="text/css">code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }</style>


    <footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            &copy; 2020-2021 CodingMarathon. 版权所有

            
            &nbsp;<i class="fa fa-area-chart"></i>&nbsp;站点总字数:&nbsp;
            <span class="white-color">28.6k</span>
            

            <br>
            <span id="sitetime"></span>

            
            
            <br>
            
            <span id="busuanzi_container_site_pv" style='display:none'>
                <i class="fa fa-heart-o"></i>
                本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
            <span id="busuanzi_container_site_uv" style='display:none'>
                人次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.
            </span>
            
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/CodingMarathon" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fa fa-github"></i>
    </a>



    <a href="mailto:991971906@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fa fa-envelope-open"></i>
    </a>



    <a href="https://zhihu.com/people/Elenstone" class="tooltipped" target="_blank" data-tooltip="访问我的知乎" data-position="top" data-delay="50">
        <i class="fa fa-inverse">知</i>
    </a>



    <a href="http://wpa.qq.com/msgrd?v=3&uin=991971906&site=qq&menu=yes" class="tooltipped" target="_blank" data-tooltip="访问我的知乎" data-position="top" data-delay="50">
        <i class="fa fa-qq"></i>
    </a>



    <a href="https://weibo.com/换个名字用" class="tooltipped" target="_blank" data-tooltip="关注我的微博" data-position="top" data-delay="50">
        <i class="fa fa-weibo"></i>
    </a>



    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fa fa-rss"></i>
    </a>
</div>
    </div>
</footer>

<div class="progress-bar"></div>

<!-- 不蒜子计数初始值纠正 -->
<script>
    $(document).ready(function () {

        var int = setInterval(fixCount, 50);
        var pvcountOffset = 80000;
        var uvcountOffset = 20000;

        function fixCount() {
            if (document.getElementById("busuanzi_container_site_pv").style.display != "none") {
                $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + pvcountOffset);
                clearInterval(int);
            }
            if ($("#busuanzi_container_site_pv").css("display") != "none") {
                $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + uvcountOffset); // 加上初始数据 
                clearInterval(int);
            }
        }
    });
</script>

<script language=javascript>
    function siteTime() {
        window.setTimeout("siteTime()", 1000);
        var seconds = 1000;
        var minutes = seconds * 60;
        var hours = minutes * 60;
        var days = hours * 24;
        var years = days * 365;
        var today = new Date();
        var todayYear = today.getFullYear();
        var todayMonth = today.getMonth() + 1;
        var todayDate = today.getDate();
        var todayHour = today.getHours();
        var todayMinute = today.getMinutes();
        var todaySecond = today.getSeconds();
        /* Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)
        year - 作为date对象的年份，为4位年份值
        month - 0-11之间的整数，做为date对象的月份
        day - 1-31之间的整数，做为date对象的天数
        hours - 0(午夜24点)-23之间的整数，做为date对象的小时数
        minutes - 0-59之间的整数，做为date对象的分钟数
        seconds - 0-59之间的整数，做为date对象的秒数
        microseconds - 0-999之间的整数，做为date对象的毫秒数 */
        var t1 = Date.UTC(2020, 03, 25, 00, 00, 00); //北京时间2020-03-25 00:00:00
        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
        var diff = t2 - t1;
        var diffYears = Math.floor(diff / years);
        var diffDays = Math.floor((diff / days) - diffYears * 365);
        var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
        var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) / minutes);
        var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours - diffMinutes * minutes) / seconds);
        document.getElementById("sitetime").innerHTML = "本站已运行 " + diffYears + " 年 " + diffDays + " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
    }/*因为建站时间还没有一年，就将之注释掉了。需要的可以取消*/
    siteTime();
</script>

    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fa fa-angle-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <script type="text/javascript"> var OriginTitile = document.title, st; document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "FoolNLP叫你快回来！", clearTimeout(st)) : (document.title = "FoolNLP欢迎你！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) })
    </script>

    <!-- Global site tag (gtag.js) - Google Analytics -->

<script async src="https://www.googletagmanager.com/gtag/js?id="></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
        dataLayer.push(arguments);
    }

    gtag('js', new Date());
    gtag('config', '');
</script>



    
    <script src="/libs/others/clicklove.js"></script>
    

    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    <!-- 雪花特效 -->
    

</body>

</html>